{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../TransportNets\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.style.use('seaborn-bright')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import h5py\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "from Models.NVP import NVP\n",
    "from Probability.MCMC import RTO_MH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualizing joint distribution p(m,y) where \n",
    "# dim(m) = 3, dim(y) = 6\n",
    "file = h5py.File('BeamSamples.h5','r')\n",
    "joint_samps = np.array(file['Samples/'])\n",
    "scatter_matrix(pd.DataFrame(joint_samps[::100,:]), figsize=(10,10), alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make target density and latent density\n",
    "target = tf.constant(joint_samps[::5,:],dtype=tf.float32)\n",
    "\n",
    "num_samples = target.shape[0] # Number of Target Samples\n",
    "dim = target.shape[1] # Dimensionality of Data\n",
    "\n",
    "latent = tf.random.normal([num_samples,dim],mean=0.0,stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "nvp = NVP(num_masked=4, output_dim=dim, num_layers=10,neuron_list=[500,500])\n",
    "\n",
    "# Create optimizer and compile nvp with it\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-06)\n",
    "nvp.compile(opt)\n",
    "\n",
    "# Perform a forward pass to initialize variables\n",
    "_ = nvp(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training options\n",
    "n_epochs = 1\n",
    "batch_size = 50\n",
    "\n",
    "# Put the target data in a format the tf likes.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(target)\n",
    "dataset = dataset.shuffle(buffer_size=5000).batch(batch_size)\n",
    "\n",
    "# Train the model with the new callback\n",
    "nvp.batch_norm_mode(True)\n",
    "history = nvp.fit(dataset, epochs=n_epochs)  # Pass callback to training\n",
    "\n",
    "# Set the training variables to not update when doing passes\n",
    "nvp.batch_norm_mode(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "R = tf.random.normal([500,dim],mean=0.0,stddev=1.0)\n",
    "x_forward = nvp(R)\n",
    "scatter_matrix(pd.DataFrame(x_forward.numpy()), figsize=(10,10))\n",
    "plt.savefig('Euler-Beam-joint-density-nvp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseStd = .01\n",
    "S = noiseStd*tf.eye(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rto = RTO_MH(nvp, 9, 6, 100, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_acc, X_cond = rto.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(15,5))\n",
    "m1,m2,m3 = tuple(rto.joint_sample[0,:(rto.n-rto.m)])\n",
    "counts,bins = np.histogram(X_cond[:,0],50,density=True)\n",
    "axs[0].hist(bins[:-1],bins,weights=counts)\n",
    "x = np.linspace(m1,m1,100)\n",
    "y = np.linspace(0,max(counts),100)\n",
    "axs[0].plot(x,y,'r--',label='true obs')\n",
    "axs[0].set_xlabel('m1')\n",
    "axs[0].legend()\n",
    "counts,bins = np.histogram(X_cond[:,1],50,density=True)\n",
    "axs[1].hist(bins[:-1],bins,weights=counts)\n",
    "x = np.linspace(m2,m2,100)\n",
    "y = np.linspace(0,max(counts),100)\n",
    "axs[1].plot(x,y,'r--',label='true obs')\n",
    "axs[1].set_xlabel('m2')\n",
    "axs[1].legend()\n",
    "counts,bins = np.histogram(X_cond[:,2],50,density=True)\n",
    "plt.hist(bins[:-1],bins,weights=counts)\n",
    "x = np.linspace(m3,m3,100)\n",
    "y = np.linspace(0,max(counts),100)\n",
    "axs[2].plot(x,y,'r--',label='true obs')\n",
    "axs[2].set_xlabel('m3')\n",
    "axs[2].legend()\n",
    "plt.suptitle('Number of Samples: %d\\n Acceptance Rate: %0.3f'%(rto.n_samples,rto.n_acc/rto.n_samples))\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.savefig('Euler_Beam_RTO_MH_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
